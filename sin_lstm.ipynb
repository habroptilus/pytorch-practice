{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 20, 1)\n",
      "(480, 1)\n"
     ]
    }
   ],
   "source": [
    "EPOCH_NUM = 10\n",
    "HIDDEN_SIZE = 5\n",
    "BATCH_SIZE = 100 # 分割した時系列をいくつミニバッチに取り込むか\n",
    "INPUT_LENGTH = 20 # ミニバッチで分割する時系列数\n",
    "\n",
    "# 教師データ\n",
    "train_data = np.array([np.sin(i*2*np.pi/50) for i in range(50)]*10)\n",
    "\n",
    "# 教師データを変換\n",
    "train_x, train_t = [], []\n",
    "for i in range(0, len(train_data)-INPUT_LENGTH):\n",
    "    train_x.append(train_data[i:i+INPUT_LENGTH])\n",
    "    train_t.append(train_data[i+INPUT_LENGTH])\n",
    "train_x = np.array(train_x, dtype=\"float32\")\n",
    "train_t = np.array(train_t, dtype=\"float32\")\n",
    "N = len(train_x)\n",
    "\n",
    "train_x=train_x.reshape(N,INPUT_LENGTH,1)#これしないと(data_num, sep_len, )となってしまう\n",
    "train_t=train_t.reshape(N,1)\n",
    "print(train_x.shape)\n",
    "print(train_t.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "クラス定義\n",
    "lstmの出力が、シーケンスででてくるけど、欲しいのは最終セルの出力だけなんだよなあ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinLstm(nn.Module):\n",
    "    def __init__(self, seq_size, hidden_size, out_size):\n",
    "        # クラスの初期化\n",
    "        # :param seq_size: 入力時系列のサイズ\n",
    "        # :param hidden_size: 隠れ層のサイズ\n",
    "        # :param out_size: 出力層のサイズ\n",
    "        super(SinLstm, self).__init__()\n",
    "        self.lstm = torch.nn.LSTM(hidden_size= hidden_size,input_size=1,batch_first=True)\n",
    "        self.dense= torch.nn.Linear(hidden_size, out_size)\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: 入力時系列\n",
    "        outputs, (h_n,c_n) = self.lstm(x)\n",
    "        h_n=h_n.squeeze()\n",
    "        y=self.dense(h_n)\n",
    "        return y\n",
    "\n",
    "    def reset(self):\n",
    "        # メモリの初期化\n",
    "        self.hidden = (Variable(torch.zeros(1, 1, self.hidden_size)), Variable(torch.zeros(1, 1, self.hidden_size))) # h, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SinLstm(\n",
      "  (lstm): LSTM(1, 5, batch_first=True)\n",
      "  (dense): Linear(in_features=5, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = SinLstm(seq_size=INPUT_LENGTH, hidden_size=HIDDEN_SIZE, out_size=1)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "tensor(0.5403)\n",
      "tensor(0.4474)\n",
      "tensor(0.5103)\n",
      "tensor(0.5417)\n",
      "tensor(0.4580)\n",
      "tensor(0.4837)\n",
      "tensor(0.4901)\n",
      "tensor(0.4697)\n",
      "tensor(0.4334)\n",
      "tensor(0.5226)\n"
     ]
    }
   ],
   "source": [
    "# 学習開始\n",
    "print(\"Train\")\n",
    "for epoch in range(EPOCH_NUM):\n",
    "    # ミニバッチ学習\n",
    "    x, t = [], []\n",
    "    #  ミニバッチ学習データとして、BATCH_SIZE個用意する\n",
    "    for i in range(BATCH_SIZE):\n",
    "        index = np.random.randint(0, N) # ランダムな箇所\n",
    "        x.append(train_x[index]) # INPUT_LENGTH分の時系列を取り出す\n",
    "        t.append(train_t[index])\n",
    "    x = np.array(x, dtype=\"float32\")\n",
    "    t = np.array(t, dtype=\"float32\")\n",
    "    x = Variable(torch.from_numpy(x))\n",
    "    t = Variable(torch.from_numpy(t))\n",
    "    total_loss = 0\n",
    "    model.reset() # メモリの初期化\n",
    "    y = model(x)#xのshapeは(batch_size, seq_len, input_dim)となっていなければいけない\n",
    "    loss = criterion(y, t)\n",
    "    loss.backward()\n",
    "    total_loss += loss.data\n",
    "    optimizer.step()\n",
    "    print(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
