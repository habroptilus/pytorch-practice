{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adultdデータに対してMLPを用いて分類してみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES_NUM=81\n",
    "EPOCHS_NUM=50\n",
    "BATCH_SIZE=2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "X=pd.read_csv(\"./data/adultd_bindata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_encode(y):\n",
    "    \"\"\"\n",
    "    labelが数値で与えられている場合にそれをonehotベクトルにencodeする。\n",
    "    (labelが複数ある場合)\n",
    "    \"\"\"\n",
    "    y = np.array(y).reshape(1, -1)\n",
    "    y = y.transpose()\n",
    "    encoder = OneHotEncoder(n_values=max(y)+1)\n",
    "    y = encoder.fit_transform(y).toarray()\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data  :   x:16281 y:16281\n",
      "train  :  x:14652 y:14652 s:14652\n",
      "test   :   x:1629 y:1629 s:1629\n",
      "(16281, 81)\n",
      "(16281,)\n"
     ]
    }
   ],
   "source": [
    "# create dataset\n",
    "x=np.array(X.iloc[:, 0:FEATURES_NUM])\n",
    "y=np.array(X[\"y\"])\n",
    "s=np.array(X[\"s\"])\n",
    "#y=onehot_encode(y)内部で勝手にラベルは変換されるぽいからこれいらない\n",
    "print(\"data  :   x:{} y:{}\".format(len(x),len(y)))\n",
    "x_train, x_test, y_train, y_test ,s_train,s_test= train_test_split(x, y, s,test_size=0.1)\n",
    "print(\"train  :  x:{} y:{} s:{}\".format(len(x_train),len(y_train),len(s_train)))\n",
    "print(\"test   :   x:{} y:{} s:{}\".format(len(x_test),len(y_test),len(s_test)))\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "TEST_BATCH_SIZE=len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = torch.utils.data.TensorDataset(torch.from_numpy(x_train).float(), torch.from_numpy(y_train).long())\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test = torch.utils.data.TensorDataset(torch.from_numpy(x_test).float(), torch.from_numpy(y_test).long())\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size=TEST_BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (l1): Linear(in_features=81, out_features=40, bias=True)\n",
      "  (l2): Linear(in_features=40, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(FEATURES_NUM, 40) # 入力層から隠れ層へ\n",
    "        self.l2 = nn.Linear(40, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, FEATURES_NUM)\n",
    "        x = F.relu(self.l1(x))\n",
    "        x=self.l2(x)\n",
    "        return x\n",
    "    \n",
    "model = MLP()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# コスト関数と最適化手法を定義\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch1 loss=181229.56649184227\n",
      "epoch2 loss=5.459144055843353\n",
      "epoch3 loss=5.3813722133636475\n",
      "epoch4 loss=5.3097785115242\n",
      "epoch5 loss=5.244743883609772\n",
      "epoch6 loss=5.179376244544983\n",
      "epoch7 loss=5.120151698589325\n",
      "epoch8 loss=5.0642513036727905\n",
      "epoch9 loss=5.021057307720184\n",
      "epoch10 loss=4.9737274050712585\n",
      "epoch11 loss=4.93659508228302\n",
      "epoch12 loss=4.895706653594971\n",
      "epoch13 loss=4.854106962680817\n",
      "epoch14 loss=4.8385180830955505\n",
      "epoch15 loss=4.807818830013275\n",
      "epoch16 loss=4.769539475440979\n",
      "epoch17 loss=4.749043703079224\n",
      "epoch18 loss=4.723015904426575\n",
      "epoch19 loss=4.694417774677277\n",
      "epoch20 loss=4.675016760826111\n",
      "epoch21 loss=4.652465879917145\n",
      "epoch22 loss=4.626520037651062\n",
      "epoch23 loss=4.62596070766449\n",
      "epoch24 loss=4.607298195362091\n",
      "epoch25 loss=4.581234931945801\n",
      "epoch26 loss=4.56935727596283\n",
      "epoch27 loss=4.569323182106018\n",
      "epoch28 loss=4.552716374397278\n",
      "epoch29 loss=4.546347081661224\n",
      "epoch30 loss=4.533331751823425\n",
      "epoch31 loss=4.518056869506836\n",
      "epoch32 loss=4.5142635107040405\n",
      "epoch33 loss=4.495603263378143\n",
      "epoch34 loss=4.509671628475189\n",
      "epoch35 loss=4.486303448677063\n",
      "epoch36 loss=4.487870931625366\n",
      "epoch37 loss=4.481715083122253\n",
      "epoch38 loss=4.451491892337799\n",
      "epoch39 loss=4.46774435043335\n",
      "epoch40 loss=4.456511437892914\n",
      "epoch41 loss=4.439146876335144\n",
      "epoch42 loss=4.44425904750824\n",
      "epoch43 loss=4.451825559139252\n",
      "epoch44 loss=4.437907040119171\n",
      "epoch45 loss=4.44256055355072\n",
      "epoch46 loss=4.436392545700073\n",
      "epoch47 loss=4.423732757568359\n",
      "epoch48 loss=4.427292764186859\n",
      "epoch49 loss=4.432191431522369\n",
      "epoch50 loss=4.430617988109589\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS_NUM):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # Variableに変換\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "        \n",
    "        # 勾配情報をリセット\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 順伝播\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # コスト関数を使ってロスを計算する\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # 逆伝播\n",
    "        loss.backward()\n",
    "        \n",
    "        # パラメータの更新\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    print(\"epoch{} loss={}\".format(epoch+1,running_loss))\n",
    "    running_loss = 0.0\n",
    "            \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 1261 / 1629 = 0.774095\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "for data in test_loader:\n",
    "    inputs, labels = data\n",
    "    outputs = model(Variable(inputs))\n",
    "    _, predicted= torch.max(outputs.data,1)#2番目の引数はどの次元について最大のものを取ってくるかを指定している(axis的なサムシング)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "    \n",
    "print('Accuracy %d / %d = %f' % (correct, total, correct.item() / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
