{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = MNIST('mnist', train=True, download=True, transform=transforms.ToTensor())\n",
    "train_loader = DataLoader(train_data,\n",
    "                         batch_size=4,\n",
    "                         shuffle=True)\n",
    "test_data = MNIST('mnist', train=False, download=True, transform=transforms.ToTensor())\n",
    "test_loader = DataLoader(test_data,\n",
    "                         batch_size=4,\n",
    "                         shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Split: train\n",
      "    Root Location: mnist\n",
      "    Transforms (if any): ToTensor()\n",
      "    Target Transforms (if any): None\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x112b96be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_iter = iter(train_loader)\n",
    "images, labels = data_iter.next()\n",
    "\n",
    "# matplotlibで1つ目のデータを可視化してみる\n",
    "npimg = images[0].numpy()\n",
    "npimg = npimg.reshape((28, 28))\n",
    "plt.imshow(npimg, cmap='gray')\n",
    "print('Label:', labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (l1): Linear(in_features=784, out_features=50, bias=True)\n",
      "  (l2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MlpMnist(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(28 * 28, 50) # 入力層から隠れ層へ\n",
    "        self.l2 = nn.Linear(50, 10) # 隠れ層から出力層へ\n",
    "        \n",
    "    def forward(self, x):# Nはバッチサイズ　データひとつのシェイプは(1,28,28)\n",
    "        x = x.view(-1, 28 * 28) # テンソルのリサイズ: (N, 1, 28, 28) --> (N, 784)\n",
    "        x = F.relu(self.l1(x))\n",
    "        x = self.l2(x)\n",
    "        return x\n",
    "    \n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# コスト関数と最適化手法を定義\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 5000 loss: 10.159\n",
      "1 10000 loss: 8.486\n",
      "1 15000 loss: 8.268\n",
      "2 5000 loss: 8.191\n",
      "2 10000 loss: 8.181\n",
      "2 15000 loss: 8.043\n",
      "3 5000 loss: 7.863\n",
      "3 10000 loss: 7.827\n",
      "3 15000 loss: 7.795\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(3):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # Variableに変換\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "        \n",
    "        # 勾配情報をリセット\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 順伝播\n",
    "        outputs = net(inputs)\n",
    "        \n",
    "        # コスト関数を使ってロスを計算する\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # 逆伝播\n",
    "        loss.backward()\n",
    "        \n",
    "        # パラメータの更新\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.data[0]\n",
    "        \n",
    "        if i % 5000 == 4999:\n",
    "            print('%d %d loss: %.3f' % (epoch + 1, i + 1, running_loss / 1000))\n",
    "            running_loss = 0.0\n",
    "            \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 9201 / 10000 = 0.920100\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "for data in test_loader:\n",
    "    inputs, labels = data\n",
    "    outputs = net(Variable(inputs))\n",
    "    _, predicted= torch.max(outputs.data,1)#2番目の引数はどの次元について最大のものを取ってくるかを指定している(axis的なサムシング)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "    \n",
    "print('Accuracy %d / %d = %f' % (correct, total, correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
