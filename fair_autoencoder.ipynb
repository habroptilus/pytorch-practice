{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fairnessを考慮したデータ表現を得るencoderをneural netを使って構築する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-6f2c6f3e98c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.utils import save_image\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "if cuda:\n",
    "    print('cuda is available!')\n",
    "    \n",
    "num_epochs = 20\n",
    "batch_size = 128\n",
    "learning_rate = 0.001\n",
    "FEATURES_NUM=81\n",
    "A_x=1\n",
    "A_y=1\n",
    "A_z=1\n",
    "out_dir = './result/fair_autoencoder'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class fair_autoencoder(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(FEATURES_NUM, 40),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(40, 20),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(20, 10),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(10, 5),\n",
    "            nn.Softmax())\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(5, 10),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(10, 20),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(20, 40),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(40, FEATURES_NUM),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.l1 = nn.Linear(5, 2) \n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        xhat = self.decoder(z)\n",
    "        y=self.l1(z)\n",
    "        return y,xhat,z\n",
    "\n",
    "model = fair_autoencoder()\n",
    "if cuda:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = my_loss_func\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                             lr=learning_rate,\n",
    "                             weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_loss_func(y,labels,x,xhat,z):\n",
    "    L_x=nn.MSELoss(x,xhat,size_average=False)# 再構成誤差\n",
    "    L_y=nn.CrossEntropyLoss(y,labels,size_average=False) # 負の対数尤度\n",
    "    L_z=compute_Lz(z,x) # 公平性制約\n",
    "    return A_x*L_x+A_y*L_y+A_z*L_z\n",
    "\n",
    "def compute_Lz(z,x):\n",
    "    Z_0=[]\n",
    "    Z_1=[]\n",
    "    for i in range(x):\n",
    "        if x[i][FEATURES_NUM-1]==0:\n",
    "            Z_0.append(z[i])\n",
    "        else:\n",
    "            Z_1.append(z[i])\n",
    "    M_0=torch.mean(Z_0)\n",
    "    M_1=torch.mean(Z_1)\n",
    "    Lz=nn.L1Loss(M_1,M_0,size_average=False)\n",
    "    return Lz"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
